{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12245048-3a03-4656-a8d4-363dfbfb3858",
   "metadata": {},
   "source": [
    "# Hands-on Activity 8.1: Aggregating Data with Pandas\n",
    "\n",
    "**NAME** : De Guzman, Aero Kent D.\\\n",
    "**DATE CREATED** : 04/12/2025\\\n",
    "**DATE SUBMITTED** : 04/12/2025\\\n",
    "**INSTRUCTOR** : Engr. Roman Richard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b67072a-c1b5-4aa1-9cde-504c19db88f2",
   "metadata": {},
   "source": [
    "## PROCEDURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 822,
   "id": "35592d11-a824-457c-9c53-afcfbe824e92",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (619721792.py, line 55)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[822], line 55\u001b[1;36m\u001b[0m\n\u001b[1;33m    \"\"\"ies\u001b[0m\n\u001b[1;37m       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Provide some comments here about the results of the procedures.\n",
    "\n",
    "# 8.1 Weather Data Collection\n",
    "\n",
    "# Under this module, the procedures are similar to how to scrape data from a website such as obtain their url as well as\n",
    "# but the difference is that the data retrieved are now both being entered into a database using sql.\n",
    "\n",
    "# 8.2 Querying and Merging\n",
    "\n",
    "# Under this module, the two functions under pandas are explained, specifically the Query() and Merge() function wherein\n",
    "# the query is simply a simplified variation on how you would construct calculations and combinations towards both columns\n",
    "# and values of a dataframe with the difference being that the process to compelete it enables it to be both faster and \n",
    "# easier to complete by removing the need to specify the use of some or either frames.\n",
    "\n",
    "# The merge() function on the other hand is a helpful function that makes two different dataframe join in with one another\n",
    "# on either side. There are also additional parameters present on this function such as which specific column would you\n",
    "# like for the two columns to join together, what would you like the values to do such as only show the similar values, drop\n",
    "# it, or just show all of them, as well as the position of the new columns.\n",
    "\r",
    "# \n",
    "8.3 Dataframe Operatios\n",
    "# \n",
    "Under this module, the different operations regarding the use of the dataframes are discussed such as how to properly# \n",
    "construct an arithmetic operations through one or more columns/rows in order to retrieve a desired value. Additionally,# \n",
    "operations to help better visualize a value is also discussed such as the use of a cut() function that divides and# \n",
    "segragates a targetted column of your choosing which can be helpful in understanding both the partioning and deviations# \n",
    "of a given values for data synthesis as well as the use of the apply() function which was used in previous activites which# \n",
    "functions by simply needing functions as its parameters which it will apply to the connected column. The rolling() function# \n",
    "is also discussed which is used for rolling window computation hence the same such as computing for values for every # \n",
    "3 days for a month were in it will return the sum for every 3 days. And lastly is the Pipes( which is also similar to \n",
    "# the apply function as well as such that you are now using the function as a parameter as well as the values you will want\n",
    "# to pass through to that function, this will be useful when it comes to futher simplifying a code to make it shorter\n",
    "# and easier on the eyes by ensuring more spaces will be freed.\n",
    "s# \r\n",
    "8.4 Aggregionsns# \n",
    "\n",
    "Under this module, the agg function is shown which makes computations such as mean, sum, max, and mean simplier to complet# e\n",
    "especially in a straight linear code rather than assigning them indivually. It is similar to the apply function where yo# u\n",
    "will simply insert the functions for calculations within it such as mean and sum. Additionally, the groupby function i# s\n",
    "shown which is helps in visualizing large amounts of data by selecting only specific columns in order to show either individuall# y\n",
    "or the total values based on a provided calculation such as grouping by something based on age then selecting their grade# s\n",
    "in order to obtain the means for each age group. Filter() function is also discussed briefly which is used in order to d# o\n",
    "what it says which is to filter a selected column,row, or table to only show the inserted parameters within that table. Lastl# y\n",
    "is the Pivot and Crosstable which is similar to the groupby function such that they also aids in helping to visualize a data b# y\n",
    "the Pivot Table selecting specific column to pivot and be the index to show only the provided column and the Crosstabl# e\n",
    "being similar in nature but are utilized for each ability to provide insights based on the used calculation provided such a# s\n",
    "either utilizing it for frequency or for a provided arithmentic function (e.g. for meann# s\r\n",
    "8.5 T Series \n",
    "# r\n",
    "\n",
    "Under this module, it was taught under here how to carry out operations and calculations when dealing with time datas su# ch\n",
    "as providing how exactly to both select as well as use them when it comes to either extracting them to use for filterati# on\n",
    "to select only those data as well as to know the ranges in order to better visualize the frequencies of these da\n",
    "\"\"\"ies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d771739b-edb7-453a-9412-b60bac16c1e2",
   "metadata": {},
   "source": [
    "## SUPPLEMENTARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e691ecb4-7461-4242-a07f-2720323598aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the needed modules\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fdc7dbf-0611-4b04-8c83-2ef6eea6e363",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mag</th>\n",
       "      <th>magType</th>\n",
       "      <th>time</th>\n",
       "      <th>place</th>\n",
       "      <th>tsunami</th>\n",
       "      <th>parsed_place</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5566</th>\n",
       "      <td>4.9</td>\n",
       "      <td>mb</td>\n",
       "      <td>1538065400600</td>\n",
       "      <td>194km W of Ile Hunter, New Caledonia</td>\n",
       "      <td>0</td>\n",
       "      <td>New Caledonia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3035</th>\n",
       "      <td>4.9</td>\n",
       "      <td>mb</td>\n",
       "      <td>1538589168370</td>\n",
       "      <td>58km NNW of Ust'-Kamchatsk Staryy, Russia</td>\n",
       "      <td>0</td>\n",
       "      <td>Russia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5312</th>\n",
       "      <td>4.9</td>\n",
       "      <td>mb</td>\n",
       "      <td>1538119717550</td>\n",
       "      <td>57km N of Palu, Indonesia</td>\n",
       "      <td>0</td>\n",
       "      <td>Indonesia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6447</th>\n",
       "      <td>4.9</td>\n",
       "      <td>mb</td>\n",
       "      <td>1537900187320</td>\n",
       "      <td>108km ENE of Kiunga, Papua New Guinea</td>\n",
       "      <td>0</td>\n",
       "      <td>Papua New Guinea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4953</th>\n",
       "      <td>4.9</td>\n",
       "      <td>mb</td>\n",
       "      <td>1538196034210</td>\n",
       "      <td>Kuril Islands</td>\n",
       "      <td>0</td>\n",
       "      <td>Kuril Islands</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>6.5</td>\n",
       "      <td>mww</td>\n",
       "      <td>1539213362130</td>\n",
       "      <td>148km S of Severo-Kuril'sk, Russia</td>\n",
       "      <td>1</td>\n",
       "      <td>Russia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4363</th>\n",
       "      <td>6.7</td>\n",
       "      <td>mww</td>\n",
       "      <td>1538304744240</td>\n",
       "      <td>263km NNE of Ndoi Island, Fiji</td>\n",
       "      <td>1</td>\n",
       "      <td>Fiji</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>6.7</td>\n",
       "      <td>mww</td>\n",
       "      <td>1539429023560</td>\n",
       "      <td>262km NW of Ozernovskiy, Russia</td>\n",
       "      <td>1</td>\n",
       "      <td>Russia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>837</th>\n",
       "      <td>7.0</td>\n",
       "      <td>mww</td>\n",
       "      <td>1539204500290</td>\n",
       "      <td>117km E of Kimbe, Papua New Guinea</td>\n",
       "      <td>1</td>\n",
       "      <td>Papua New Guinea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5263</th>\n",
       "      <td>7.5</td>\n",
       "      <td>mww</td>\n",
       "      <td>1538128963480</td>\n",
       "      <td>78km N of Palu, Indonesia</td>\n",
       "      <td>1</td>\n",
       "      <td>Indonesia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mag magType           time                                      place  \\\n",
       "5566  4.9      mb  1538065400600       194km W of Ile Hunter, New Caledonia   \n",
       "3035  4.9      mb  1538589168370  58km NNW of Ust'-Kamchatsk Staryy, Russia   \n",
       "5312  4.9      mb  1538119717550                  57km N of Palu, Indonesia   \n",
       "6447  4.9      mb  1537900187320      108km ENE of Kiunga, Papua New Guinea   \n",
       "4953  4.9      mb  1538196034210                              Kuril Islands   \n",
       "...   ...     ...            ...                                        ...   \n",
       "799   6.5     mww  1539213362130         148km S of Severo-Kuril'sk, Russia   \n",
       "4363  6.7     mww  1538304744240             263km NNE of Ndoi Island, Fiji   \n",
       "118   6.7     mww  1539429023560            262km NW of Ozernovskiy, Russia   \n",
       "837   7.0     mww  1539204500290         117km E of Kimbe, Papua New Guinea   \n",
       "5263  7.5     mww  1538128963480                  78km N of Palu, Indonesia   \n",
       "\n",
       "      tsunami      parsed_place  \n",
       "5566        0     New Caledonia  \n",
       "3035        0            Russia  \n",
       "5312        0         Indonesia  \n",
       "6447        0  Papua New Guinea  \n",
       "4953        0     Kuril Islands  \n",
       "...       ...               ...  \n",
       "799         1            Russia  \n",
       "4363        1              Fiji  \n",
       "118         1            Russia  \n",
       "837         1  Papua New Guinea  \n",
       "5263        1         Indonesia  \n",
       "\n",
       "[195 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. With the earthquakes.csv file, select all the earthquakes in Japan with a magType of mb and a magnitude of 4.9 or greater.\n",
    "\n",
    "quakes = pd.read_csv('datasets/earthquakes.csv')\n",
    "quakes.query('`mag` >= 4.9').sort_values('mag') # added sort to see that 4.9 above are really selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ddcd0842-2449-41c3-bdb5-8c06620bbe12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9331\n",
      "mag\n",
      "3-4    2489\n",
      "2-3    2172\n",
      "4-5     906\n",
      "1-2     821\n",
      "5-6     251\n",
      "0-1     131\n",
      "6-7      31\n",
      "7-8       2\n",
      "Name: count, dtype: int64\n",
      "6803\n"
     ]
    }
   ],
   "source": [
    "# 2. Create bins for each full number of magnitude (for example, the first bin is 0-1, the second is 1-2, and so on) with a magType of ml and count how many are in each bin.\n",
    "quakesMl = quakes[quakes['magType'] == 'ml'].sort_values('mag', ascending = True).dropna().copy()\n",
    "print((quakes.value_counts()).sum())\n",
    "quakesBin = pd.cut(quakesMl.mag, bins = 8, labels = ['0-1','1-2','2-3','3-4','4-5','5-6','6-7','7-8'])\n",
    "print(quakesBin.value_counts())\n",
    "print((quakesBin.value_counts()).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16548147-e0a9-4655-b09e-13fe98462cd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ticker</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AAPL</th>\n",
       "      <td>187.038674</td>\n",
       "      <td>231.6645</td>\n",
       "      <td>145.9639</td>\n",
       "      <td>186.986218</td>\n",
       "      <td>8539383858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMZN</th>\n",
       "      <td>1644.072669</td>\n",
       "      <td>2050.5000</td>\n",
       "      <td>1170.5100</td>\n",
       "      <td>1641.726175</td>\n",
       "      <td>1418040266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FB</th>\n",
       "      <td>171.454424</td>\n",
       "      <td>218.6200</td>\n",
       "      <td>123.0200</td>\n",
       "      <td>171.510936</td>\n",
       "      <td>6949682394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GOOG</th>\n",
       "      <td>1113.554104</td>\n",
       "      <td>1273.8900</td>\n",
       "      <td>970.1100</td>\n",
       "      <td>1113.225139</td>\n",
       "      <td>437403914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NFLX</th>\n",
       "      <td>319.620533</td>\n",
       "      <td>423.2056</td>\n",
       "      <td>195.4200</td>\n",
       "      <td>319.290299</td>\n",
       "      <td>2879045091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               open       high        low        close      volume\n",
       "ticker                                                            \n",
       "AAPL     187.038674   231.6645   145.9639   186.986218  8539383858\n",
       "AMZN    1644.072669  2050.5000  1170.5100  1641.726175  1418040266\n",
       "FB       171.454424   218.6200   123.0200   171.510936  6949682394\n",
       "GOOG    1113.554104  1273.8900   970.1100  1113.225139   437403914\n",
       "NFLX     319.620533   423.2056   195.4200   319.290299  2879045091"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. Using the faang.csv file, group by the ticker and resample to monthly frequency. Make the following aggregations:\n",
    "\n",
    "faangdf = pd.read_csv('datasets/faang.csv') # add the value then the function you would like to use\n",
    "faangdf.groupby('ticker').agg({'open'   : 'mean', # 3.1 Mean of the opening price\n",
    "                               'high'   : 'max',  # 3.2 Maximum of the high price\n",
    "                               'low'    : 'min',  # 3.3 Minimum of the low price\n",
    "                               'close'  : 'mean', # 3.4 Mean of the closing price\n",
    "                               'volume' : 'sum'}) # 3.5 Sum of the volume traded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa2b16fa-8cd1-42f3-adf1-f123de90bb1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>magType</th>\n",
       "      <th>mb</th>\n",
       "      <th>mb_lg</th>\n",
       "      <th>md</th>\n",
       "      <th>mh</th>\n",
       "      <th>ml</th>\n",
       "      <th>ms_20</th>\n",
       "      <th>mw</th>\n",
       "      <th>mwb</th>\n",
       "      <th>mwr</th>\n",
       "      <th>mww</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tsunami</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.6</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.11</td>\n",
       "      <td>1.1</td>\n",
       "      <td>4.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.83</td>\n",
       "      <td>5.8</td>\n",
       "      <td>4.8</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.1</td>\n",
       "      <td>5.7</td>\n",
       "      <td>4.41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "magType   mb  mb_lg    md   mh   ml  ms_20    mw  mwb  mwr  mww\n",
       "tsunami                                                        \n",
       "0        5.6    3.5  4.11  1.1  4.2    NaN  3.83  5.8  4.8  6.0\n",
       "1        6.1    NaN   NaN  NaN  5.1    5.7  4.41  NaN  NaN  7.5"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. Build a crosstab with the earthquake data between the tsunami column and the magType column. Rather than showing the frequency count, show the maximum\n",
    "#    magnitude that was observed for each combination. Put the magType along the columns.\n",
    "\n",
    "pd.crosstab(index = quakes.tsunami, columns = quakes.magType, values = quakes.mag, aggfunc = 'max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 832,
   "id": "934faba9-7fc0-4053-a0d2-9f37c040da4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  open    high     low     close        volume\n",
      "date                                                          \n",
      "2018-01-02         NaN     NaN     NaN       NaN           NaN\n",
      "2018-01-03         NaN     NaN     NaN       NaN           NaN\n",
      "2018-01-04         NaN     NaN     NaN       NaN           NaN\n",
      "2018-01-05         NaN     NaN     NaN       NaN           NaN\n",
      "2018-01-08         NaN     NaN     NaN       NaN           NaN\n",
      "2018-01-09         NaN     NaN     NaN       NaN           NaN\n",
      "2018-01-10         NaN     NaN     NaN       NaN           NaN\n",
      "2018-01-11         NaN     NaN     NaN       NaN           NaN\n",
      "2018-01-12         NaN     NaN     NaN       NaN           NaN\n",
      "2018-01-16         NaN     NaN     NaN       NaN           NaN\n",
      "2018-01-17         NaN     NaN     NaN       NaN           NaN\n",
      "2018-01-18         NaN     NaN     NaN       NaN           NaN\n",
      "2018-01-19         NaN     NaN     NaN       NaN           NaN\n",
      "2018-01-22         NaN     NaN     NaN       NaN           NaN\n",
      "2018-01-23         NaN     NaN     NaN       NaN           NaN\n",
      "2018-01-24         NaN     NaN     NaN       NaN           NaN\n",
      "2018-01-25         NaN     NaN     NaN       NaN           NaN\n",
      "2018-01-26         NaN     NaN     NaN       NaN           NaN\n",
      "2018-01-29         NaN     NaN     NaN       NaN           NaN\n",
      "2018-01-30         NaN     NaN     NaN       NaN           NaN\n",
      "2018-01-31         NaN     NaN     NaN       NaN           NaN\n",
      "2018-02-01         NaN     NaN     NaN       NaN           NaN\n",
      "2018-02-02         NaN     NaN     NaN       NaN           NaN\n",
      "2018-02-05         NaN     NaN     NaN       NaN           NaN\n",
      "2018-02-06         NaN     NaN     NaN       NaN           NaN\n",
      "2018-02-07         NaN     NaN     NaN       NaN           NaN\n",
      "2018-02-08         NaN     NaN     NaN       NaN           NaN\n",
      "2018-02-09         NaN     NaN     NaN       NaN           NaN\n",
      "2018-02-12         NaN     NaN     NaN       NaN           NaN\n",
      "2018-02-13         NaN     NaN     NaN       NaN           NaN\n",
      "2018-02-14         NaN     NaN     NaN       NaN           NaN\n",
      "2018-02-15         NaN     NaN     NaN       NaN           NaN\n",
      "2018-02-16         NaN     NaN     NaN       NaN           NaN\n",
      "2018-02-20         NaN     NaN     NaN       NaN           NaN\n",
      "2018-02-21         NaN     NaN     NaN       NaN           NaN\n",
      "2018-02-22         NaN     NaN     NaN       NaN           NaN\n",
      "2018-02-23         NaN     NaN     NaN       NaN           NaN\n",
      "2018-02-26         NaN     NaN     NaN       NaN           NaN\n",
      "2018-02-27         NaN     NaN     NaN       NaN           NaN\n",
      "2018-02-28         NaN     NaN     NaN       NaN           NaN\n",
      "2018-03-01         NaN     NaN     NaN       NaN           NaN\n",
      "2018-03-02         NaN     NaN     NaN       NaN           NaN\n",
      "2018-03-05         NaN     NaN     NaN       NaN           NaN\n",
      "2018-03-06         NaN     NaN     NaN       NaN           NaN\n",
      "2018-03-07         NaN     NaN     NaN       NaN           NaN\n",
      "2018-03-08         NaN     NaN     NaN       NaN           NaN\n",
      "2018-03-09         NaN     NaN     NaN       NaN           NaN\n",
      "2018-03-12         NaN     NaN     NaN       NaN           NaN\n",
      "2018-03-13         NaN     NaN     NaN       NaN           NaN\n",
      "2018-03-14         NaN     NaN     NaN       NaN           NaN\n",
      "2018-03-15         NaN     NaN     NaN       NaN           NaN\n",
      "2018-03-16         NaN     NaN     NaN       NaN           NaN\n",
      "2018-03-19         NaN     NaN     NaN       NaN           NaN\n",
      "2018-03-20         NaN     NaN     NaN       NaN           NaN\n",
      "2018-03-21         NaN     NaN     NaN       NaN           NaN\n",
      "2018-03-22         NaN     NaN     NaN       NaN           NaN\n",
      "2018-03-23         NaN     NaN     NaN       NaN           NaN\n",
      "2018-03-26         NaN     NaN     NaN       NaN           NaN\n",
      "2018-03-27         NaN     NaN     NaN       NaN           NaN\n",
      "2018-03-28  179.877667  195.32  149.02  179.8805  1.949076e+09\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-02</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-03</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-04</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-05</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-08</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-24</th>\n",
       "      <td>1078.653333</td>\n",
       "      <td>1209.96</td>\n",
       "      <td>970.11</td>\n",
       "      <td>1074.657833</td>\n",
       "      <td>119478286.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-26</th>\n",
       "      <td>1075.272333</td>\n",
       "      <td>1209.96</td>\n",
       "      <td>970.11</td>\n",
       "      <td>1072.091000</td>\n",
       "      <td>120470927.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-27</th>\n",
       "      <td>1072.226667</td>\n",
       "      <td>1209.96</td>\n",
       "      <td>970.11</td>\n",
       "      <td>1069.567167</td>\n",
       "      <td>121223100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-28</th>\n",
       "      <td>1069.871000</td>\n",
       "      <td>1206.41</td>\n",
       "      <td>970.11</td>\n",
       "      <td>1066.850000</td>\n",
       "      <td>120948958.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-31</th>\n",
       "      <td>1067.303667</td>\n",
       "      <td>1197.51</td>\n",
       "      <td>970.11</td>\n",
       "      <td>1064.061000</td>\n",
       "      <td>121186466.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1255 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   open     high     low        close       volume\n",
       "date                                                              \n",
       "2018-01-02          NaN      NaN     NaN          NaN          NaN\n",
       "2018-01-03          NaN      NaN     NaN          NaN          NaN\n",
       "2018-01-04          NaN      NaN     NaN          NaN          NaN\n",
       "2018-01-05          NaN      NaN     NaN          NaN          NaN\n",
       "2018-01-08          NaN      NaN     NaN          NaN          NaN\n",
       "...                 ...      ...     ...          ...          ...\n",
       "2018-12-24  1078.653333  1209.96  970.11  1074.657833  119478286.0\n",
       "2018-12-26  1075.272333  1209.96  970.11  1072.091000  120470927.0\n",
       "2018-12-27  1072.226667  1209.96  970.11  1069.567167  121223100.0\n",
       "2018-12-28  1069.871000  1206.41  970.11  1066.850000  120948958.0\n",
       "2018-12-31  1067.303667  1197.51  970.11  1064.061000  121186466.0\n",
       "\n",
       "[1255 rows x 5 columns]"
      ]
     },
     "execution_count": 832,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5. Calculate the rolling 60-day aggregations of OHLC data by ticker for the FAANG data. Use the same aggregations as exercise no. 3.\n",
    "faangRoll = faangdf.copy()\n",
    "faangRoll['date'] = pd.to_datetime(faangRoll['date'])\n",
    "faangRoll.set_index('date', inplace = True)\n",
    "faangRoll = faangRoll.rolling(60).agg({'open'   : 'mean', # 3.1 Mean of the opening price\n",
    "                                       'high'   : 'max',  # 3.2 Maximum of the high price\n",
    "                                       'low'    : 'min',  # 3.3 Minimum of the low price\n",
    "                                       'close'  : 'mean', # 3.4 Mean of the closing price\n",
    "                                       'volume' : 'sum'}) # 3.5 Sum of the volume traded\n",
    "print(faangRoll.iloc[0:60]) # to see that we are really rolling by intervals of 60 days, it is NaN since it hasn't been 60+ days yet\n",
    "faangRoll                   # here, it can be seen here the summary after all those rolling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 834,
   "id": "b9e8dbff-f47f-4c57-9cfd-19273fa3b6cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>open</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ticker</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AAPL</th>\n",
       "      <td>186.986218</td>\n",
       "      <td>188.906858</td>\n",
       "      <td>185.135729</td>\n",
       "      <td>187.038674</td>\n",
       "      <td>3.402145e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMZN</th>\n",
       "      <td>1641.726175</td>\n",
       "      <td>1662.839801</td>\n",
       "      <td>1619.840398</td>\n",
       "      <td>1644.072669</td>\n",
       "      <td>5.649563e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FB</th>\n",
       "      <td>171.510936</td>\n",
       "      <td>173.615298</td>\n",
       "      <td>169.303110</td>\n",
       "      <td>171.454424</td>\n",
       "      <td>2.768798e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GOOG</th>\n",
       "      <td>1113.225139</td>\n",
       "      <td>1125.777649</td>\n",
       "      <td>1101.001594</td>\n",
       "      <td>1113.554104</td>\n",
       "      <td>1.742645e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NFLX</th>\n",
       "      <td>319.290299</td>\n",
       "      <td>325.224583</td>\n",
       "      <td>313.187273</td>\n",
       "      <td>319.620533</td>\n",
       "      <td>1.147030e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              close         high          low         open        volume\n",
       "ticker                                                                  \n",
       "AAPL     186.986218   188.906858   185.135729   187.038674  3.402145e+07\n",
       "AMZN    1641.726175  1662.839801  1619.840398  1644.072669  5.649563e+06\n",
       "FB       171.510936   173.615298   169.303110   171.454424  2.768798e+07\n",
       "GOOG    1113.225139  1125.777649  1101.001594  1113.554104  1.742645e+06\n",
       "NFLX     319.290299   325.224583   313.187273   319.620533  1.147030e+07"
      ]
     },
     "execution_count": 834,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6. Create a pivot table of the FAANG data that compares the stocks. Put the ticker in the rows and show the averages of the OHLC and volume traded data.\n",
    "pd.pivot_table(faangdf, index = 'ticker', values = ['open','high','low','close','volume'], aggfunc = 'mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 836,
   "id": "d07096ca-3fe5-4c74-b500-3bc632048e7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>level_1</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NFLX</td>\n",
       "      <td>753</td>\n",
       "      <td>-2.500753</td>\n",
       "      <td>-2.516023</td>\n",
       "      <td>-2.410226</td>\n",
       "      <td>-2.416644</td>\n",
       "      <td>-0.088760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NFLX</td>\n",
       "      <td>754</td>\n",
       "      <td>-2.380291</td>\n",
       "      <td>-2.423180</td>\n",
       "      <td>-2.285793</td>\n",
       "      <td>-2.335286</td>\n",
       "      <td>-0.507606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NFLX</td>\n",
       "      <td>755</td>\n",
       "      <td>-2.296272</td>\n",
       "      <td>-2.406077</td>\n",
       "      <td>-2.234616</td>\n",
       "      <td>-2.323429</td>\n",
       "      <td>-0.959287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NFLX</td>\n",
       "      <td>756</td>\n",
       "      <td>-2.275014</td>\n",
       "      <td>-2.345607</td>\n",
       "      <td>-2.202087</td>\n",
       "      <td>-2.234303</td>\n",
       "      <td>-0.782331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NFLX</td>\n",
       "      <td>757</td>\n",
       "      <td>-2.218934</td>\n",
       "      <td>-2.295113</td>\n",
       "      <td>-2.143759</td>\n",
       "      <td>-2.192192</td>\n",
       "      <td>-1.038531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>NFLX</td>\n",
       "      <td>999</td>\n",
       "      <td>-1.571478</td>\n",
       "      <td>-1.518366</td>\n",
       "      <td>-1.627197</td>\n",
       "      <td>-1.745946</td>\n",
       "      <td>-0.339003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>NFLX</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1.735063</td>\n",
       "      <td>-1.439978</td>\n",
       "      <td>-1.677339</td>\n",
       "      <td>-1.341402</td>\n",
       "      <td>0.517040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>NFLX</td>\n",
       "      <td>1001</td>\n",
       "      <td>-1.407286</td>\n",
       "      <td>-1.417785</td>\n",
       "      <td>-1.495805</td>\n",
       "      <td>-1.302664</td>\n",
       "      <td>0.134868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>NFLX</td>\n",
       "      <td>1002</td>\n",
       "      <td>-1.248762</td>\n",
       "      <td>-1.289018</td>\n",
       "      <td>-1.297285</td>\n",
       "      <td>-1.292137</td>\n",
       "      <td>-0.085164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>NFLX</td>\n",
       "      <td>1003</td>\n",
       "      <td>-1.203817</td>\n",
       "      <td>-1.122354</td>\n",
       "      <td>-1.088531</td>\n",
       "      <td>-1.055420</td>\n",
       "      <td>0.359444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>251 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ticker  level_1      open      high       low     close    volume\n",
       "0     NFLX      753 -2.500753 -2.516023 -2.410226 -2.416644 -0.088760\n",
       "1     NFLX      754 -2.380291 -2.423180 -2.285793 -2.335286 -0.507606\n",
       "2     NFLX      755 -2.296272 -2.406077 -2.234616 -2.323429 -0.959287\n",
       "3     NFLX      756 -2.275014 -2.345607 -2.202087 -2.234303 -0.782331\n",
       "4     NFLX      757 -2.218934 -2.295113 -2.143759 -2.192192 -1.038531\n",
       "..     ...      ...       ...       ...       ...       ...       ...\n",
       "246   NFLX      999 -1.571478 -1.518366 -1.627197 -1.745946 -0.339003\n",
       "247   NFLX     1000 -1.735063 -1.439978 -1.677339 -1.341402  0.517040\n",
       "248   NFLX     1001 -1.407286 -1.417785 -1.495805 -1.302664  0.134868\n",
       "249   NFLX     1002 -1.248762 -1.289018 -1.297285 -1.292137 -0.085164\n",
       "250   NFLX     1003 -1.203817 -1.122354 -1.088531 -1.055420  0.359444\n",
       "\n",
       "[251 rows x 7 columns]"
      ]
     },
     "execution_count": 836,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 7. Calculate the Z-scores for each numeric column of Netflix's data (ticker is NFLX) using apply().\n",
    "\n",
    "nflxDF = faangdf[faangdf['ticker'] == 'NFLX'].copy()\n",
    "nflxDF.groupby('ticker')[['open','high','low','close','volume']] \\\n",
    "                        .apply(lambda x: (x - x.mean()) / x.std()).reset_index() # z-score formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 840,
   "id": "2309ef46-0499-4bcc-83d9-fcdcd943e53e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                              event\n",
      "date       ticker                                                  \n",
      "2018-03-19 FB                             Cambridge Analytica story\n",
      "2018-03-20 FB                                     FTC investigation\n",
      "2018-07-25 FB      Disappointing user growth announced after close.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>event</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th>ticker</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-02</th>\n",
       "      <th>AAPL</th>\n",
       "      <td>166.9271</td>\n",
       "      <td>169.0264</td>\n",
       "      <td>166.0442</td>\n",
       "      <td>168.9872</td>\n",
       "      <td>25555934</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-03</th>\n",
       "      <th>AAPL</th>\n",
       "      <td>169.2521</td>\n",
       "      <td>171.2337</td>\n",
       "      <td>168.6929</td>\n",
       "      <td>168.9578</td>\n",
       "      <td>29517899</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-04</th>\n",
       "      <th>AAPL</th>\n",
       "      <td>169.2619</td>\n",
       "      <td>170.1742</td>\n",
       "      <td>168.8106</td>\n",
       "      <td>169.7426</td>\n",
       "      <td>22434597</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-05</th>\n",
       "      <th>AAPL</th>\n",
       "      <td>170.1448</td>\n",
       "      <td>172.0381</td>\n",
       "      <td>169.7622</td>\n",
       "      <td>171.6751</td>\n",
       "      <td>23660018</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-08</th>\n",
       "      <th>AAPL</th>\n",
       "      <td>171.0375</td>\n",
       "      <td>172.2736</td>\n",
       "      <td>170.6255</td>\n",
       "      <td>171.0375</td>\n",
       "      <td>20567766</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-24</th>\n",
       "      <th>NFLX</th>\n",
       "      <td>242.0000</td>\n",
       "      <td>250.6500</td>\n",
       "      <td>233.6800</td>\n",
       "      <td>233.8800</td>\n",
       "      <td>9547616</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-26</th>\n",
       "      <th>NFLX</th>\n",
       "      <td>233.9200</td>\n",
       "      <td>254.5000</td>\n",
       "      <td>231.2300</td>\n",
       "      <td>253.6700</td>\n",
       "      <td>14402735</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-27</th>\n",
       "      <th>NFLX</th>\n",
       "      <td>250.1100</td>\n",
       "      <td>255.5900</td>\n",
       "      <td>240.1000</td>\n",
       "      <td>255.5650</td>\n",
       "      <td>12235217</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-28</th>\n",
       "      <th>NFLX</th>\n",
       "      <td>257.9400</td>\n",
       "      <td>261.9144</td>\n",
       "      <td>249.8000</td>\n",
       "      <td>256.0800</td>\n",
       "      <td>10987286</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-31</th>\n",
       "      <th>NFLX</th>\n",
       "      <td>260.1600</td>\n",
       "      <td>270.1001</td>\n",
       "      <td>260.0000</td>\n",
       "      <td>267.6600</td>\n",
       "      <td>13508920</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1255 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       open      high       low     close    volume event\n",
       "date       ticker                                                        \n",
       "2018-01-02 AAPL    166.9271  169.0264  166.0442  168.9872  25555934   NaN\n",
       "2018-01-03 AAPL    169.2521  171.2337  168.6929  168.9578  29517899   NaN\n",
       "2018-01-04 AAPL    169.2619  170.1742  168.8106  169.7426  22434597   NaN\n",
       "2018-01-05 AAPL    170.1448  172.0381  169.7622  171.6751  23660018   NaN\n",
       "2018-01-08 AAPL    171.0375  172.2736  170.6255  171.0375  20567766   NaN\n",
       "...                     ...       ...       ...       ...       ...   ...\n",
       "2018-12-24 NFLX    242.0000  250.6500  233.6800  233.8800   9547616   NaN\n",
       "2018-12-26 NFLX    233.9200  254.5000  231.2300  253.6700  14402735   NaN\n",
       "2018-12-27 NFLX    250.1100  255.5900  240.1000  255.5650  12235217   NaN\n",
       "2018-12-28 NFLX    257.9400  261.9144  249.8000  256.0800  10987286   NaN\n",
       "2018-12-31 NFLX    260.1600  270.1001  260.0000  267.6600  13508920   NaN\n",
       "\n",
       "[1255 rows x 6 columns]"
      ]
     },
     "execution_count": 840,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 8. Add event descriptions:\n",
    "\n",
    "# Create a dataframe with the following three columns: ticker, date, and event. The columns should have the following values:\n",
    "df8 = faangdf[['ticker','date']].query(\"date in ['2018-07-25', '2018-03-19', '2018-03-20'] and ticker == 'FB'\").copy() # ticker: 'FB'\n",
    "                                                                                                                       # date: ['2018-07-25', '2018-03-19', '2018-03-20']\n",
    "df8['event'] = df8['date'].apply(lambda x : 'Disappointing user growth announced after close.' if x == '2018-07-25' \\\n",
    "                                 else 'Cambridge Analytica story' if x == '2018-03-19' \\\n",
    "                                 else 'FTC investigation') # event: ['Disappointing user growth announced after close.', 'Cambridge Analytica story', 'FTC investigation']\n",
    "\n",
    "df8.set_index(['date', 'ticker'], inplace = True) # Set the index to ['date', 'ticker']\n",
    "print(df8)\n",
    "\n",
    "dfMerge = faangdf.copy()\n",
    "\n",
    "dfMerge = dfMerge.merge(df8, on = ['ticker','date'], how = 'outer').set_index(['date', 'ticker']) # Merge this data with the FAANG data using an outer join\n",
    "dfMerge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 808,
   "id": "d93784e9-f4f4-40b6-ab84-d49aa7d0fe5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Use the transform() method on the FAANG data to represent all the values in terms of the first date in the data. To do so, divide all the values for each ticker by the values\n",
    "# for the first date in the data for that ticker. This is referred to as an index, and the data for the first date is the base (https://ec.europa.eu/eurostat/statistics-explained/\n",
    "# index.php/ Beginners:Statisticalconcept-Indexandbaseyear). When data is in this format, we can easily see growth over time. Hint: transform() can take a function name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 842,
   "id": "96ec0726-9be1-4a8b-b0e9-9baa02aa5f83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th>ticker</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-02</th>\n",
       "      <th>AAPL</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-03</th>\n",
       "      <th>AAPL</th>\n",
       "      <td>1.013928</td>\n",
       "      <td>1.013059</td>\n",
       "      <td>1.015952</td>\n",
       "      <td>0.999826</td>\n",
       "      <td>1.155031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-04</th>\n",
       "      <th>AAPL</th>\n",
       "      <td>1.013987</td>\n",
       "      <td>1.006791</td>\n",
       "      <td>1.016661</td>\n",
       "      <td>1.004470</td>\n",
       "      <td>0.877863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-05</th>\n",
       "      <th>AAPL</th>\n",
       "      <td>1.019276</td>\n",
       "      <td>1.017818</td>\n",
       "      <td>1.022392</td>\n",
       "      <td>1.015906</td>\n",
       "      <td>0.925813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-08</th>\n",
       "      <th>AAPL</th>\n",
       "      <td>1.024624</td>\n",
       "      <td>1.019211</td>\n",
       "      <td>1.027591</td>\n",
       "      <td>1.012133</td>\n",
       "      <td>0.804814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-24</th>\n",
       "      <th>NFLX</th>\n",
       "      <td>1.234064</td>\n",
       "      <td>1.242995</td>\n",
       "      <td>1.195783</td>\n",
       "      <td>1.163177</td>\n",
       "      <td>0.870586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-26</th>\n",
       "      <th>NFLX</th>\n",
       "      <td>1.192861</td>\n",
       "      <td>1.262088</td>\n",
       "      <td>1.183246</td>\n",
       "      <td>1.261600</td>\n",
       "      <td>1.313293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-27</th>\n",
       "      <th>NFLX</th>\n",
       "      <td>1.275421</td>\n",
       "      <td>1.267493</td>\n",
       "      <td>1.228636</td>\n",
       "      <td>1.271025</td>\n",
       "      <td>1.115651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-28</th>\n",
       "      <th>NFLX</th>\n",
       "      <td>1.315349</td>\n",
       "      <td>1.298856</td>\n",
       "      <td>1.278272</td>\n",
       "      <td>1.273586</td>\n",
       "      <td>1.001860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-31</th>\n",
       "      <th>NFLX</th>\n",
       "      <td>1.326670</td>\n",
       "      <td>1.339450</td>\n",
       "      <td>1.330468</td>\n",
       "      <td>1.331178</td>\n",
       "      <td>1.231791</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1255 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       open      high       low     close    volume\n",
       "date       ticker                                                  \n",
       "2018-01-02 AAPL    1.000000  1.000000  1.000000  1.000000  1.000000\n",
       "2018-01-03 AAPL    1.013928  1.013059  1.015952  0.999826  1.155031\n",
       "2018-01-04 AAPL    1.013987  1.006791  1.016661  1.004470  0.877863\n",
       "2018-01-05 AAPL    1.019276  1.017818  1.022392  1.015906  0.925813\n",
       "2018-01-08 AAPL    1.024624  1.019211  1.027591  1.012133  0.804814\n",
       "...                     ...       ...       ...       ...       ...\n",
       "2018-12-24 NFLX    1.234064  1.242995  1.195783  1.163177  0.870586\n",
       "2018-12-26 NFLX    1.192861  1.262088  1.183246  1.261600  1.313293\n",
       "2018-12-27 NFLX    1.275421  1.267493  1.228636  1.271025  1.115651\n",
       "2018-12-28 NFLX    1.315349  1.298856  1.278272  1.273586  1.001860\n",
       "2018-12-31 NFLX    1.326670  1.339450  1.330468  1.331178  1.231791\n",
       "\n",
       "[1255 rows x 5 columns]"
      ]
     },
     "execution_count": 842,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfMerge.groupby(['ticker'])[['open','high','low','close','volume']].transform(lambda x: x / x.iloc[0]) # for each assigned ticker by groupby,\n",
    "                                                                                                       # the provided values will be divided\n",
    "                                                                                                       # by the first date of that ticker,\n",
    "                                                                                                       # since the group is located on that \n",
    "                                                                                                       # specific ticker, it will loc the first\n",
    "                                                                                                       # located in the index using iloc\n",
    "                                                                                                       # which is the first date there."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
