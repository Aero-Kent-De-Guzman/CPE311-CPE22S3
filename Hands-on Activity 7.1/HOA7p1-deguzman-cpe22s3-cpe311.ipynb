{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f929ef3-ee17-465c-a418-b2ced06da695",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# **MODULE 7: DATA WRANGLING WITH PANDAS**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d59923-3e2f-45b4-b7a0-13e471969bb2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## **CPE311 COMPUTATIONAL THINKING WITH PYTHON**\n",
    "\n",
    "SUBMITTED BY: De Guzman, Aero Kent\n",
    "\n",
    "PERFORMED ON: 04/06/2025\n",
    "\n",
    "SUBMITTED ON: 04/07/2025\n",
    "\n",
    "\n",
    "SUBMITTED TO: Engr. Roman M. Richard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f720cda-c0fd-4f8c-83f1-0c3200dd5189",
   "metadata": {},
   "source": [
    "## **7.1 Supplementary Activity**\r\n",
    "\r\n",
    "Using the datasets provided, perform the following exercises."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b481b4-23c2-482e-b8cf-18013c5460a1",
   "metadata": {},
   "source": [
    "### **Exercise 1**\r\n",
    "\r\n",
    "We want to look at data for the Facebook, Apple, Amazon, Netflix, and Google (FAANG) stocks, but we were given each as a separate CSV file. Combine them into a single file and store the dataframe of the FAANG data as faang for the rest of the exercises:\r\n",
    "\r\n",
    "1. Read each file in.\r\n",
    "2. Add a column to each dataframe, called ticker, indicating the ticker symbol it is for (Apple's\r\n",
    "is AAPL, for example). This is how you look up a stock. Each file's name is also the ticker\r\n",
    "symbol, so be sure to capitalize it.\r\n",
    "3. Append them together into a single dataframe.\r\n",
    "4. Save the result in a CSV file called faang.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "18a656da-d379-455e-925f-286ae48da316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date      open      high       low     close    volume\n",
      "0  2018-01-02  166.9271  169.0264  166.0442  168.9872  25555934\n",
      "1  2018-01-03  169.2521  171.2337  168.6929  168.9578  29517899\n",
      "2  2018-01-04  169.2619  170.1742  168.8106  169.7426  22434597\n",
      "3  2018-01-05  170.1448  172.0381  169.7622  171.6751  23660018\n",
      "4  2018-01-08  171.0375  172.2736  170.6255  171.0375  20567766\n",
      "         date     open     high      low    close   volume\n",
      "0  2018-01-02  1172.00  1190.00  1170.51  1189.01  2694494\n",
      "1  2018-01-03  1188.30  1205.49  1188.30  1204.20  3108793\n",
      "2  2018-01-04  1205.00  1215.87  1204.66  1209.59  3022089\n",
      "3  2018-01-05  1217.51  1229.14  1210.00  1229.14  3544743\n",
      "4  2018-01-08  1236.00  1253.08  1232.03  1246.87  4279475\n",
      "         date    open    high       low   close    volume\n",
      "0  2018-01-02  177.68  181.58  177.5500  181.42  18151903\n",
      "1  2018-01-03  181.88  184.78  181.3300  184.67  16886563\n",
      "2  2018-01-04  184.90  186.21  184.0996  184.33  13880896\n",
      "3  2018-01-05  185.59  186.90  184.9300  186.85  13574535\n",
      "4  2018-01-08  187.20  188.90  186.3300  188.28  17994726\n",
      "         date     open     high      low    close   volume\n",
      "0  2018-01-02  1048.34  1066.94  1045.23  1065.00  1237564\n",
      "1  2018-01-03  1064.31  1086.29  1063.21  1082.48  1430170\n",
      "2  2018-01-04  1088.00  1093.57  1084.00  1086.40  1004605\n",
      "3  2018-01-05  1094.00  1104.25  1092.00  1102.23  1279123\n",
      "4  2018-01-08  1102.23  1111.27  1101.62  1106.94  1047603\n",
      "         date    open    high       low   close    volume\n",
      "0  2018-01-02  196.10  201.65  195.4200  201.07  10966889\n",
      "1  2018-01-03  202.05  206.21  201.5000  205.05   8591369\n",
      "2  2018-01-04  206.20  207.05  204.0006  205.63   6029616\n",
      "3  2018-01-05  207.25  210.02  205.5900  209.99   7033240\n",
      "4  2018-01-08  210.02  212.50  208.4400  212.05   5580178\n"
     ]
    }
   ],
   "source": [
    "# 1. Read each file in.\n",
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    'AAPL' : pd.read_csv('datasets/aapl.csv'),\n",
    "    'AMZN' : pd.read_csv('datasets/amzn.csv'),\n",
    "    'FB'   : pd.read_csv('datasets/fb.csv'),\n",
    "    'GOOG' : pd.read_csv('datasets/goog.csv'),\n",
    "    'NFLX' : pd.read_csv('datasets/nflx.csv')\n",
    "}\n",
    "\n",
    "for i in data:\n",
    "    print(data[i].head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a8c2f885-6bf0-4935-8d12-00827b1b7e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date      open      high       low     close    volume ticker\n",
      "0  2018-01-02  166.9271  169.0264  166.0442  168.9872  25555934   AAPL\n",
      "1  2018-01-03  169.2521  171.2337  168.6929  168.9578  29517899   AAPL\n",
      "2  2018-01-04  169.2619  170.1742  168.8106  169.7426  22434597   AAPL\n",
      "3  2018-01-05  170.1448  172.0381  169.7622  171.6751  23660018   AAPL\n",
      "4  2018-01-08  171.0375  172.2736  170.6255  171.0375  20567766   AAPL\n",
      "         date     open     high      low    close   volume ticker\n",
      "0  2018-01-02  1172.00  1190.00  1170.51  1189.01  2694494   AMZN\n",
      "1  2018-01-03  1188.30  1205.49  1188.30  1204.20  3108793   AMZN\n",
      "2  2018-01-04  1205.00  1215.87  1204.66  1209.59  3022089   AMZN\n",
      "3  2018-01-05  1217.51  1229.14  1210.00  1229.14  3544743   AMZN\n",
      "4  2018-01-08  1236.00  1253.08  1232.03  1246.87  4279475   AMZN\n",
      "         date    open    high       low   close    volume ticker\n",
      "0  2018-01-02  177.68  181.58  177.5500  181.42  18151903     FB\n",
      "1  2018-01-03  181.88  184.78  181.3300  184.67  16886563     FB\n",
      "2  2018-01-04  184.90  186.21  184.0996  184.33  13880896     FB\n",
      "3  2018-01-05  185.59  186.90  184.9300  186.85  13574535     FB\n",
      "4  2018-01-08  187.20  188.90  186.3300  188.28  17994726     FB\n",
      "         date     open     high      low    close   volume ticker\n",
      "0  2018-01-02  1048.34  1066.94  1045.23  1065.00  1237564   GOOG\n",
      "1  2018-01-03  1064.31  1086.29  1063.21  1082.48  1430170   GOOG\n",
      "2  2018-01-04  1088.00  1093.57  1084.00  1086.40  1004605   GOOG\n",
      "3  2018-01-05  1094.00  1104.25  1092.00  1102.23  1279123   GOOG\n",
      "4  2018-01-08  1102.23  1111.27  1101.62  1106.94  1047603   GOOG\n",
      "         date    open    high       low   close    volume ticker\n",
      "0  2018-01-02  196.10  201.65  195.4200  201.07  10966889   NFLX\n",
      "1  2018-01-03  202.05  206.21  201.5000  205.05   8591369   NFLX\n",
      "2  2018-01-04  206.20  207.05  204.0006  205.63   6029616   NFLX\n",
      "3  2018-01-05  207.25  210.02  205.5900  209.99   7033240   NFLX\n",
      "4  2018-01-08  210.02  212.50  208.4400  212.05   5580178   NFLX\n"
     ]
    }
   ],
   "source": [
    "# 2. Add a column to each dataframe, called ticker, indicating the ticker symbol\n",
    "# it is for (Apple's is AAPL, for example). This is how you look up a stock.\n",
    "# Each file's name is also the ticker symbol, so be sure to capitalize it.\n",
    "\n",
    "for i in data:\n",
    "    data[i] = data[i].assign(ticker = i)\n",
    "\n",
    "for i in data:\n",
    "    print(data[i].head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d8c495c0-c6a5-44cc-8c59-8e1d3922e504",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>166.9271</td>\n",
       "      <td>169.0264</td>\n",
       "      <td>166.0442</td>\n",
       "      <td>168.9872</td>\n",
       "      <td>25555934</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>169.2521</td>\n",
       "      <td>171.2337</td>\n",
       "      <td>168.6929</td>\n",
       "      <td>168.9578</td>\n",
       "      <td>29517899</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>169.2619</td>\n",
       "      <td>170.1742</td>\n",
       "      <td>168.8106</td>\n",
       "      <td>169.7426</td>\n",
       "      <td>22434597</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>170.1448</td>\n",
       "      <td>172.0381</td>\n",
       "      <td>169.7622</td>\n",
       "      <td>171.6751</td>\n",
       "      <td>23660018</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-08</td>\n",
       "      <td>171.0375</td>\n",
       "      <td>172.2736</td>\n",
       "      <td>170.6255</td>\n",
       "      <td>171.0375</td>\n",
       "      <td>20567766</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1250</th>\n",
       "      <td>2018-12-24</td>\n",
       "      <td>242.0000</td>\n",
       "      <td>250.6500</td>\n",
       "      <td>233.6800</td>\n",
       "      <td>233.8800</td>\n",
       "      <td>9547616</td>\n",
       "      <td>NFLX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1251</th>\n",
       "      <td>2018-12-26</td>\n",
       "      <td>233.9200</td>\n",
       "      <td>254.5000</td>\n",
       "      <td>231.2300</td>\n",
       "      <td>253.6700</td>\n",
       "      <td>14402735</td>\n",
       "      <td>NFLX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1252</th>\n",
       "      <td>2018-12-27</td>\n",
       "      <td>250.1100</td>\n",
       "      <td>255.5900</td>\n",
       "      <td>240.1000</td>\n",
       "      <td>255.5650</td>\n",
       "      <td>12235217</td>\n",
       "      <td>NFLX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1253</th>\n",
       "      <td>2018-12-28</td>\n",
       "      <td>257.9400</td>\n",
       "      <td>261.9144</td>\n",
       "      <td>249.8000</td>\n",
       "      <td>256.0800</td>\n",
       "      <td>10987286</td>\n",
       "      <td>NFLX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1254</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>260.1600</td>\n",
       "      <td>270.1001</td>\n",
       "      <td>260.0000</td>\n",
       "      <td>267.6600</td>\n",
       "      <td>13508920</td>\n",
       "      <td>NFLX</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1255 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date      open      high       low     close    volume ticker\n",
       "0     2018-01-02  166.9271  169.0264  166.0442  168.9872  25555934   AAPL\n",
       "1     2018-01-03  169.2521  171.2337  168.6929  168.9578  29517899   AAPL\n",
       "2     2018-01-04  169.2619  170.1742  168.8106  169.7426  22434597   AAPL\n",
       "3     2018-01-05  170.1448  172.0381  169.7622  171.6751  23660018   AAPL\n",
       "4     2018-01-08  171.0375  172.2736  170.6255  171.0375  20567766   AAPL\n",
       "...          ...       ...       ...       ...       ...       ...    ...\n",
       "1250  2018-12-24  242.0000  250.6500  233.6800  233.8800   9547616   NFLX\n",
       "1251  2018-12-26  233.9200  254.5000  231.2300  253.6700  14402735   NFLX\n",
       "1252  2018-12-27  250.1100  255.5900  240.1000  255.5650  12235217   NFLX\n",
       "1253  2018-12-28  257.9400  261.9144  249.8000  256.0800  10987286   NFLX\n",
       "1254  2018-12-31  260.1600  270.1001  260.0000  267.6600  13508920   NFLX\n",
       "\n",
       "[1255 rows x 7 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. Append them together into a single dataframe.\n",
    "\n",
    "FAANG_df = pd.DataFrame(pd.concat([apple_df,amazon_df,facebook_df,google_df,netflix_df], ignore_index = True))\n",
    "FAANG_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b0e592cc-ade8-4530-b2e3-ba3e5d9c15d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Save the result in a CSV file called faang.csv.\n",
    "\n",
    "FAANG_df.to_csv('datasets/faang.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6c3fdc-6996-42c2-a89e-9931fd12025c",
   "metadata": {},
   "source": [
    "### **Exercise 2**\r\n",
    "\r\n",
    "* With faang, use type conversion to change the date column into a datetime and the volume column into integers. Then, sort by date and ticker.\r\n",
    "* Find the seven rows with the highest value for volume.\r\n",
    "* Right now, the data is somewhere between long and wide format. Use melt() to make it completely long format. Hint: date and ticker are our ID variables (they uniquely identify\r\n",
    "each row). We need to melt the rest so that we don't have separate columns for open, high, low, close, and volume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "037b3a8c-f31f-41a7-ac83-8ed735906708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date      datetime64[ns]\n",
      "volume             int64\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>166.9271</td>\n",
       "      <td>169.0264</td>\n",
       "      <td>166.0442</td>\n",
       "      <td>168.9872</td>\n",
       "      <td>25555934</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>1172.0000</td>\n",
       "      <td>1190.0000</td>\n",
       "      <td>1170.5100</td>\n",
       "      <td>1189.0100</td>\n",
       "      <td>2694494</td>\n",
       "      <td>AMZN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>177.6800</td>\n",
       "      <td>181.5800</td>\n",
       "      <td>177.5500</td>\n",
       "      <td>181.4200</td>\n",
       "      <td>18151903</td>\n",
       "      <td>FB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>1048.3400</td>\n",
       "      <td>1066.9400</td>\n",
       "      <td>1045.2300</td>\n",
       "      <td>1065.0000</td>\n",
       "      <td>1237564</td>\n",
       "      <td>GOOG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>196.1000</td>\n",
       "      <td>201.6500</td>\n",
       "      <td>195.4200</td>\n",
       "      <td>201.0700</td>\n",
       "      <td>10966889</td>\n",
       "      <td>NFLX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1250</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>157.8529</td>\n",
       "      <td>158.6794</td>\n",
       "      <td>155.8117</td>\n",
       "      <td>157.0663</td>\n",
       "      <td>35003466</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1251</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>1510.8000</td>\n",
       "      <td>1520.7600</td>\n",
       "      <td>1487.0000</td>\n",
       "      <td>1501.9700</td>\n",
       "      <td>6954507</td>\n",
       "      <td>AMZN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1252</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>134.4500</td>\n",
       "      <td>134.6400</td>\n",
       "      <td>129.9500</td>\n",
       "      <td>131.0900</td>\n",
       "      <td>24625308</td>\n",
       "      <td>FB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1253</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>1050.9600</td>\n",
       "      <td>1052.7000</td>\n",
       "      <td>1023.5900</td>\n",
       "      <td>1035.6100</td>\n",
       "      <td>1493722</td>\n",
       "      <td>GOOG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1254</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>260.1600</td>\n",
       "      <td>270.1001</td>\n",
       "      <td>260.0000</td>\n",
       "      <td>267.6600</td>\n",
       "      <td>13508920</td>\n",
       "      <td>NFLX</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1255 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date       open       high        low      close    volume ticker\n",
       "0    2018-01-02   166.9271   169.0264   166.0442   168.9872  25555934   AAPL\n",
       "1    2018-01-02  1172.0000  1190.0000  1170.5100  1189.0100   2694494   AMZN\n",
       "2    2018-01-02   177.6800   181.5800   177.5500   181.4200  18151903     FB\n",
       "3    2018-01-02  1048.3400  1066.9400  1045.2300  1065.0000   1237564   GOOG\n",
       "4    2018-01-02   196.1000   201.6500   195.4200   201.0700  10966889   NFLX\n",
       "...         ...        ...        ...        ...        ...       ...    ...\n",
       "1250 2018-12-31   157.8529   158.6794   155.8117   157.0663  35003466   AAPL\n",
       "1251 2018-12-31  1510.8000  1520.7600  1487.0000  1501.9700   6954507   AMZN\n",
       "1252 2018-12-31   134.4500   134.6400   129.9500   131.0900  24625308     FB\n",
       "1253 2018-12-31  1050.9600  1052.7000  1023.5900  1035.6100   1493722   GOOG\n",
       "1254 2018-12-31   260.1600   270.1001   260.0000   267.6600  13508920   NFLX\n",
       "\n",
       "[1255 rows x 7 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. With faang, use type conversion to change the date column into a datetime\n",
    "# and the volume column into integers. Then, sort by date and ticker.\n",
    "\n",
    "df2 = pd.read_csv('datasets/faang.csv')\n",
    "\n",
    "df2.date = df2.date.apply(pd.to_datetime)\n",
    "print(df2[['date','volume']].dtypes) # volume is already in integers...\n",
    "\n",
    "df2 = df2.sort_values(['date','ticker']).reset_index(drop = True)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "b1943bd9-32c7-45d9-9215-ffa16855b258",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>2018-07-26</td>\n",
       "      <td>174.8900</td>\n",
       "      <td>180.1300</td>\n",
       "      <td>173.7500</td>\n",
       "      <td>176.2600</td>\n",
       "      <td>169803668</td>\n",
       "      <td>FB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>2018-03-20</td>\n",
       "      <td>167.4700</td>\n",
       "      <td>170.2000</td>\n",
       "      <td>161.9500</td>\n",
       "      <td>168.1500</td>\n",
       "      <td>129851768</td>\n",
       "      <td>FB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>2018-03-26</td>\n",
       "      <td>160.8200</td>\n",
       "      <td>161.1000</td>\n",
       "      <td>149.0200</td>\n",
       "      <td>160.0600</td>\n",
       "      <td>126116634</td>\n",
       "      <td>FB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>2018-03-21</td>\n",
       "      <td>164.8000</td>\n",
       "      <td>173.4000</td>\n",
       "      <td>163.3000</td>\n",
       "      <td>169.3900</td>\n",
       "      <td>106598834</td>\n",
       "      <td>FB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910</th>\n",
       "      <td>2018-09-21</td>\n",
       "      <td>219.0727</td>\n",
       "      <td>219.6482</td>\n",
       "      <td>215.6097</td>\n",
       "      <td>215.9768</td>\n",
       "      <td>96246748</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1225</th>\n",
       "      <td>2018-12-21</td>\n",
       "      <td>156.1901</td>\n",
       "      <td>157.4845</td>\n",
       "      <td>148.9909</td>\n",
       "      <td>150.0862</td>\n",
       "      <td>95744384</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1060</th>\n",
       "      <td>2018-11-02</td>\n",
       "      <td>207.9295</td>\n",
       "      <td>211.9978</td>\n",
       "      <td>203.8414</td>\n",
       "      <td>205.8755</td>\n",
       "      <td>91328654</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           date      open      high       low     close     volume ticker\n",
       "712  2018-07-26  174.8900  180.1300  173.7500  176.2600  169803668     FB\n",
       "267  2018-03-20  167.4700  170.2000  161.9500  168.1500  129851768     FB\n",
       "287  2018-03-26  160.8200  161.1000  149.0200  160.0600  126116634     FB\n",
       "272  2018-03-21  164.8000  173.4000  163.3000  169.3900  106598834     FB\n",
       "910  2018-09-21  219.0727  219.6482  215.6097  215.9768   96246748   AAPL\n",
       "1225 2018-12-21  156.1901  157.4845  148.9909  150.0862   95744384   AAPL\n",
       "1060 2018-11-02  207.9295  211.9978  203.8414  205.8755   91328654   AAPL"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Find the seven rows with the highest value for volume.\n",
    "df2.sort_values('volume', ascending = False).head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "e60dda20-a11e-4a6f-8d25-47336ff6f4ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>ticker</th>\n",
       "      <th>variable</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>open</td>\n",
       "      <td>1.669271e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>open</td>\n",
       "      <td>1.172000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>FB</td>\n",
       "      <td>open</td>\n",
       "      <td>1.776800e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>GOOG</td>\n",
       "      <td>open</td>\n",
       "      <td>1.048340e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>NFLX</td>\n",
       "      <td>open</td>\n",
       "      <td>1.961000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6270</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>volume</td>\n",
       "      <td>3.500347e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6271</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>volume</td>\n",
       "      <td>6.954507e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6272</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>FB</td>\n",
       "      <td>volume</td>\n",
       "      <td>2.462531e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6273</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>GOOG</td>\n",
       "      <td>volume</td>\n",
       "      <td>1.493722e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6274</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>NFLX</td>\n",
       "      <td>volume</td>\n",
       "      <td>1.350892e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6275 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date ticker variable         value\n",
       "0    2018-01-02   AAPL     open  1.669271e+02\n",
       "1    2018-01-02   AMZN     open  1.172000e+03\n",
       "2    2018-01-02     FB     open  1.776800e+02\n",
       "3    2018-01-02   GOOG     open  1.048340e+03\n",
       "4    2018-01-02   NFLX     open  1.961000e+02\n",
       "...         ...    ...      ...           ...\n",
       "6270 2018-12-31   AAPL   volume  3.500347e+07\n",
       "6271 2018-12-31   AMZN   volume  6.954507e+06\n",
       "6272 2018-12-31     FB   volume  2.462531e+07\n",
       "6273 2018-12-31   GOOG   volume  1.493722e+06\n",
       "6274 2018-12-31   NFLX   volume  1.350892e+07\n",
       "\n",
       "[6275 rows x 4 columns]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. Right now, the data is somewhere between long and wide format. Use melt()\n",
    "# to make it completely long format. Hint: date and ticker are our ID variables\n",
    "# (they uniquely identify each row). We need to melt the rest so that we don't\n",
    "# have separate columns for open, high, low, close, and volume.\n",
    "\n",
    "pd.melt(df2, ['date','ticker'], ['open', 'high', 'low', 'close', 'volume'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac95bd27-23e0-46ac-856d-93e0b2b44660",
   "metadata": {},
   "source": [
    "### **Exercise 3**\r\n",
    "\r\n",
    "* Using web scraping, search for the list of the hospitals, their address and contact information. Save the list in a new csv file, hospitals.csv.\r\n",
    "* Using the generated hospitals.csv, convert the csv file into pandas dataframe. Prepare the data using the necessary preprocessing techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "d3fe1a86-6ce1-42f0-b18b-3ce8824cc6fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kaggle\n",
      "  Downloading kaggle-1.7.4.2-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting bleach (from kaggle)\n",
      "  Downloading bleach-6.2.0-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting certifi>=14.05.14 (from kaggle)\n",
      "  Downloading certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting charset-normalizer (from kaggle)\n",
      "  Downloading charset_normalizer-3.4.1-cp312-cp312-win_amd64.whl.metadata (36 kB)\n",
      "Collecting idna (from kaggle)\n",
      "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting protobuf (from kaggle)\n",
      "  Downloading protobuf-6.30.2-cp310-abi3-win_amd64.whl.metadata (593 bytes)\n",
      "Collecting python-dateutil>=2.5.3 (from kaggle)\n",
      "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting python-slugify (from kaggle)\n",
      "  Downloading python_slugify-8.0.4-py2.py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting requests (from kaggle)\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: setuptools>=21.0.0 in c:\\users\\userr\\anaconda3\\envs\\deguzman-cpe22s3-cpe311\\lib\\site-packages (from kaggle) (75.8.0)\n",
      "Collecting six>=1.10 (from kaggle)\n",
      "  Downloading six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting text-unidecode (from kaggle)\n",
      "  Downloading text_unidecode-1.3-py2.py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting tqdm (from kaggle)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting urllib3>=1.15.1 (from kaggle)\n",
      "  Downloading urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting webencodings (from kaggle)\n",
      "  Downloading webencodings-0.5.1-py2.py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting colorama (from tqdm->kaggle)\n",
      "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
      "Downloading kaggle-1.7.4.2-py3-none-any.whl (173 kB)\n",
      "Downloading certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
      "Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "Downloading six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
      "Downloading urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
      "Downloading bleach-6.2.0-py3-none-any.whl (163 kB)\n",
      "Downloading charset_normalizer-3.4.1-cp312-cp312-win_amd64.whl (102 kB)\n",
      "Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "Downloading protobuf-6.30.2-cp310-abi3-win_amd64.whl (431 kB)\n",
      "Downloading python_slugify-8.0.4-py2.py3-none-any.whl (10 kB)\n",
      "Downloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
      "Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Installing collected packages: webencodings, text-unidecode, urllib3, six, python-slugify, protobuf, idna, colorama, charset-normalizer, certifi, bleach, tqdm, requests, python-dateutil, kaggle\n",
      "Successfully installed bleach-6.2.0 certifi-2025.1.31 charset-normalizer-3.4.1 colorama-0.4.6 idna-3.10 kaggle-1.7.4.2 protobuf-6.30.2 python-dateutil-2.9.0.post0 python-slugify-8.0.4 requests-2.32.3 six-1.17.0 text-unidecode-1.3 tqdm-4.67.1 urllib3-2.3.0 webencodings-0.5.1\n"
     ]
    }
   ],
   "source": [
    "# 1. Using web scraping, search for the list of the hospitals, their address and\n",
    "# contact information. Save the list in a new csv file, hospitals.csv.\n",
    "\n",
    "# I do not know what exactly web scraping means but from what I have seen, it is\n",
    "# extracting data/sets online through python by using a code as a medium of\n",
    "# direct extraction as well as their url/links\n",
    "\n",
    "# to install the web scrapped data from kaggle, the instruction can be found in\n",
    "# their documentation at their website at https://www.kaggle.com/docs/api#authentication\n",
    "# below are the specific links that I have actually used found within that documentation...\n",
    "\n",
    "# 1. In order to run commands such as retrieving dataset(s)\n",
    "# https://www.kaggle.com/docs/api#authentication:~:text=package%20and%20authentication.-,Installation,below%20and%20you%E2%80%99ll%20be%20able%20to%20use%20the%20kaggle%20CLI%20tool.,-If%20you%20run\n",
    "# 2. In order to actually use/retrieve the data (public API key)\n",
    "# https://www.kaggle.com/docs/api#authentication:~:text=is%20%24PYTHON_HOME/Scripts.-,Authentication,the%20download%20of%20kaggle.json%2C%20a%20file%20containing%20your%20API%20credentials.,-If%20you%20are\n",
    "# 3. To download the datasets.\n",
    "# https://www.kaggle.com/docs/api#authentication:~:text=kaggle%20datasets%20download%20%2Dd%20%5BDATASET%5D%3A%20download%20files%20associated%20with%20a%20dataset\n",
    "\n",
    "!pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "f32ac021-aa8e-4393-8f44-e8b8a95a6195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/shuvokumarbasak2030/bd-doctor-information-doctor-directory-dataset\n",
      "License(s): MIT\n",
      "bd-doctor-information-doctor-directory-dataset.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
     ]
    }
   ],
   "source": [
    "# to  actually download the dataset.\n",
    "# this will return a KeyError: 'username' if the API key is not found in your system\n",
    "# it must be placed in C:\\Users\\<username>\\.kaggle\\\n",
    "# https://www.kaggle.com/docs/api#authentication:~:text=C%3A%5CUsers%5C%3CWindows%2Dusername%3E%5C.kaggle%5Ckaggle.json%20on%20Windows.\n",
    "# the following will retrieve a .zip file containing the dataset(s)\n",
    "\n",
    "!kaggle datasets download -d shuvokumarbasak2030/bd-doctor-information-doctor-directory-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "6edf156b-c0ea-4759-9e40-1218029bb6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.read_csv('datasets/Doctor_Directory.csv').to_csv('datasets/hospitals.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "30dd4395-aa3c-4a7c-b119-dd2c568aa26e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S/L</th>\n",
       "      <th>Post</th>\n",
       "      <th>Provider</th>\n",
       "      <th>Division</th>\n",
       "      <th>District</th>\n",
       "      <th>Upazila</th>\n",
       "      <th>facility</th>\n",
       "      <th>ProfessionalDis</th>\n",
       "      <th>ContactNo</th>\n",
       "      <th>Address</th>\n",
       "      <th>Degree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Sr. Consultant(Eye)</td>\n",
       "      <td>Dr. Mahboob Jahan Ahmed</td>\n",
       "      <td>Rajshahi</td>\n",
       "      <td>Chapai Nawabganj</td>\n",
       "      <td>Chapai Nababganj Sadar</td>\n",
       "      <td>Chapai Nababganj District Hospital</td>\n",
       "      <td>Ophthalmology</td>\n",
       "      <td>1712290927</td>\n",
       "      <td>Adhunik Sadar Hospital, Chapainawabganj</td>\n",
       "      <td>MBBS/1983,MCPS(Ophthalmology)/2001,MS(Ophthalm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Sr. Consultant(Paediatrics)</td>\n",
       "      <td>Dr. Bipad Bhanjan Karmakar</td>\n",
       "      <td>Rajshahi</td>\n",
       "      <td>Chapai Nawabganj</td>\n",
       "      <td>Chapai Nababganj Sadar</td>\n",
       "      <td>Chapai Nababganj District Hospital</td>\n",
       "      <td>Pediatrics</td>\n",
       "      <td>1556333100</td>\n",
       "      <td>Vill-Sultanabad,PO-Ghora Mara,PS-Boalia,Dist-R...</td>\n",
       "      <td>DCH(Pediatrics)/2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Jr. Consultant(Anesthesia)</td>\n",
       "      <td>Dr.Md.Monirul Islam</td>\n",
       "      <td>Rajshahi</td>\n",
       "      <td>Chapai Nawabganj</td>\n",
       "      <td>Chapai Nababganj Sadar</td>\n",
       "      <td>Chapai Nababganj District Hospital</td>\n",
       "      <td>Medical Officer</td>\n",
       "      <td>1748991574</td>\n",
       "      <td>Sadar Hospital Chapainawabganj</td>\n",
       "      <td>DA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Jr. Consultant(Surgery)</td>\n",
       "      <td>Dr. Md. Shahid-ul-islam Khan</td>\n",
       "      <td>Rajshahi</td>\n",
       "      <td>Chapai Nawabganj</td>\n",
       "      <td>Chapai Nababganj Sadar</td>\n",
       "      <td>Chapai Nababganj District Hospital</td>\n",
       "      <td>Surgery</td>\n",
       "      <td>1711003283</td>\n",
       "      <td>JUNIOR CONSULTANT, SURGERY, ADHUNIK SADAR HOSP...</td>\n",
       "      <td>MBBS/2004,FCPS(Surgery)/2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>RMO</td>\n",
       "      <td>Dr. Ayesha Julekha</td>\n",
       "      <td>Rajshahi</td>\n",
       "      <td>Chapai Nawabganj</td>\n",
       "      <td>Chapai Nababganj Sadar</td>\n",
       "      <td>Chapai Nababganj District Hospital</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1715171009</td>\n",
       "      <td>Adhuink Sadar Hospital, Chapainawabganj.</td>\n",
       "      <td>MBBS,MBBS/1984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>195</td>\n",
       "      <td>Mymensingh Medical College Hospital - Asstt. R...</td>\n",
       "      <td>Dr. Rajesh Kumar Ghose</td>\n",
       "      <td>Rajshahi</td>\n",
       "      <td>Rajshahi</td>\n",
       "      <td>Rajpara</td>\n",
       "      <td>Rajshahi Medical College Hospital</td>\n",
       "      <td>Cardiology</td>\n",
       "      <td>1715405881</td>\n",
       "      <td>2/A, Aziz Co-operative Complex, Shahbagh, Dhaka</td>\n",
       "      <td>MBBS,MBBS/2002,MD(Cardiology)/2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>196</td>\n",
       "      <td>Rajshahi Medical College Hospital - Medical Of...</td>\n",
       "      <td>Dr. Md. Ruhul Amin</td>\n",
       "      <td>Rajshahi</td>\n",
       "      <td>Rajshahi</td>\n",
       "      <td>Rajpara</td>\n",
       "      <td>Rajshahi Medical College Hospital</td>\n",
       "      <td>Medical Officer</td>\n",
       "      <td>1718242137</td>\n",
       "      <td>Moddho Naodapara, P.O: Sopura,P.S: Shah Mukhdu...</td>\n",
       "      <td>MBBS/2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>197</td>\n",
       "      <td>Rajshahi Medical College Hospital - Anesthesio...</td>\n",
       "      <td>A. K. M. Tanvirul Haque</td>\n",
       "      <td>Rajshahi</td>\n",
       "      <td>Rajshahi</td>\n",
       "      <td>Rajpara</td>\n",
       "      <td>Rajshahi Medical College Hospital</td>\n",
       "      <td>Anesthesiology</td>\n",
       "      <td>1715153845</td>\n",
       "      <td>Rajshahi Medical College Hospital</td>\n",
       "      <td>DA/2016,DA/2016,MBBS/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>198</td>\n",
       "      <td>Rajshahi Medical College Hospital - Anesthesio...</td>\n",
       "      <td>Dr. Mohammad Delowar Hossain</td>\n",
       "      <td>Rajshahi</td>\n",
       "      <td>Rajshahi</td>\n",
       "      <td>Rajpara</td>\n",
       "      <td>Rajshahi Medical College Hospital</td>\n",
       "      <td>Anesthesiology</td>\n",
       "      <td>1716856453</td>\n",
       "      <td>EMO,UHC,PANGSHA,RAJBARI</td>\n",
       "      <td>MBBS,DA(Anesthesiology)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>199</td>\n",
       "      <td>Rajshahi Medical College Hospital - Asstt. Reg...</td>\n",
       "      <td>Dr. Md. Azizul Islam</td>\n",
       "      <td>Rajshahi</td>\n",
       "      <td>Rajshahi</td>\n",
       "      <td>Rajpara</td>\n",
       "      <td>Rajshahi Medical College Hospital</td>\n",
       "      <td>General Surgery</td>\n",
       "      <td>1712988026</td>\n",
       "      <td>HOLDING-44 VILL. FAKIRPARA, PO-CHAPAI NAWABGON...</td>\n",
       "      <td>MS/2016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>199 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     S/L                                               Post  \\\n",
       "0      1                                Sr. Consultant(Eye)   \n",
       "1      2                        Sr. Consultant(Paediatrics)   \n",
       "2      3                         Jr. Consultant(Anesthesia)   \n",
       "3      4                            Jr. Consultant(Surgery)   \n",
       "4      5                                                RMO   \n",
       "..   ...                                                ...   \n",
       "194  195  Mymensingh Medical College Hospital - Asstt. R...   \n",
       "195  196  Rajshahi Medical College Hospital - Medical Of...   \n",
       "196  197  Rajshahi Medical College Hospital - Anesthesio...   \n",
       "197  198  Rajshahi Medical College Hospital - Anesthesio...   \n",
       "198  199  Rajshahi Medical College Hospital - Asstt. Reg...   \n",
       "\n",
       "                         Provider  Division          District  \\\n",
       "0         Dr. Mahboob Jahan Ahmed  Rajshahi  Chapai Nawabganj   \n",
       "1      Dr. Bipad Bhanjan Karmakar  Rajshahi  Chapai Nawabganj   \n",
       "2             Dr.Md.Monirul Islam  Rajshahi  Chapai Nawabganj   \n",
       "3    Dr. Md. Shahid-ul-islam Khan  Rajshahi  Chapai Nawabganj   \n",
       "4              Dr. Ayesha Julekha  Rajshahi  Chapai Nawabganj   \n",
       "..                            ...       ...               ...   \n",
       "194        Dr. Rajesh Kumar Ghose  Rajshahi          Rajshahi   \n",
       "195            Dr. Md. Ruhul Amin  Rajshahi          Rajshahi   \n",
       "196       A. K. M. Tanvirul Haque  Rajshahi          Rajshahi   \n",
       "197  Dr. Mohammad Delowar Hossain  Rajshahi          Rajshahi   \n",
       "198          Dr. Md. Azizul Islam  Rajshahi          Rajshahi   \n",
       "\n",
       "                    Upazila                            facility  \\\n",
       "0    Chapai Nababganj Sadar  Chapai Nababganj District Hospital   \n",
       "1    Chapai Nababganj Sadar  Chapai Nababganj District Hospital   \n",
       "2    Chapai Nababganj Sadar  Chapai Nababganj District Hospital   \n",
       "3    Chapai Nababganj Sadar  Chapai Nababganj District Hospital   \n",
       "4    Chapai Nababganj Sadar  Chapai Nababganj District Hospital   \n",
       "..                      ...                                 ...   \n",
       "194                 Rajpara   Rajshahi Medical College Hospital   \n",
       "195                 Rajpara   Rajshahi Medical College Hospital   \n",
       "196                 Rajpara   Rajshahi Medical College Hospital   \n",
       "197                 Rajpara   Rajshahi Medical College Hospital   \n",
       "198                 Rajpara   Rajshahi Medical College Hospital   \n",
       "\n",
       "     ProfessionalDis   ContactNo  \\\n",
       "0      Ophthalmology  1712290927   \n",
       "1         Pediatrics  1556333100   \n",
       "2    Medical Officer  1748991574   \n",
       "3            Surgery  1711003283   \n",
       "4                NaN  1715171009   \n",
       "..               ...         ...   \n",
       "194       Cardiology  1715405881   \n",
       "195  Medical Officer  1718242137   \n",
       "196   Anesthesiology  1715153845   \n",
       "197   Anesthesiology  1716856453   \n",
       "198  General Surgery  1712988026   \n",
       "\n",
       "                                               Address  \\\n",
       "0              Adhunik Sadar Hospital, Chapainawabganj   \n",
       "1    Vill-Sultanabad,PO-Ghora Mara,PS-Boalia,Dist-R...   \n",
       "2                       Sadar Hospital Chapainawabganj   \n",
       "3    JUNIOR CONSULTANT, SURGERY, ADHUNIK SADAR HOSP...   \n",
       "4             Adhuink Sadar Hospital, Chapainawabganj.   \n",
       "..                                                 ...   \n",
       "194    2/A, Aziz Co-operative Complex, Shahbagh, Dhaka   \n",
       "195  Moddho Naodapara, P.O: Sopura,P.S: Shah Mukhdu...   \n",
       "196                  Rajshahi Medical College Hospital   \n",
       "197                            EMO,UHC,PANGSHA,RAJBARI   \n",
       "198  HOLDING-44 VILL. FAKIRPARA, PO-CHAPAI NAWABGON...   \n",
       "\n",
       "                                                Degree  \n",
       "0    MBBS/1983,MCPS(Ophthalmology)/2001,MS(Ophthalm...  \n",
       "1                                 DCH(Pediatrics)/2002  \n",
       "2                                                   DA  \n",
       "3                         MBBS/2004,FCPS(Surgery)/2014  \n",
       "4                                       MBBS,MBBS/1984  \n",
       "..                                                 ...  \n",
       "194                 MBBS,MBBS/2002,MD(Cardiology)/2016  \n",
       "195                                          MBBS/2004  \n",
       "196                              DA/2016,DA/2016,MBBS/  \n",
       "197                            MBBS,DA(Anesthesiology)  \n",
       "198                                            MS/2016  \n",
       "\n",
       "[199 rows x 11 columns]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. Using the generated hospitals.csv, convert the csv file into pandas\n",
    "# dataframe. Prepare the data using the necessary preprocessing techniques.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "hospitalDF = pd.read_csv('datasets/hospitals.csv')\n",
    "hospitalDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bad9044-c83a-4fda-8bad-e47fd155523f",
   "metadata": {},
   "source": [
    "## **7.2 CONCLUSION**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11aaa87c-24e6-4275-8c5b-b6ea6ebf2aa0",
   "metadata": {},
   "source": [
    "To conclude the following hands on activity, it was all about data wrangling as well as data collection through python.\n",
    "In the first and second provided exercises, the task that was being asked here is to modify and entrangle the provided\n",
    "datasets in order for better and easier visualization and access by appending/joining each of them into one due to all\n",
    "of them containing and asking the same columns within which will make it easier and compatible for joining. In the first\n",
    "exercise, this was possible due to the .concat() function wherein it joins in the provided dataframes into one. I was\n",
    "supposed to use the .append() function but after search for a while, it turns out that pandas 2.0 onwards does not support\n",
    "it anymore and have removed it which is why I have used the .concat() function instead. The premise of the 1st exercise\n",
    "is simply based within that which is on how to join similar dataframes into one.\n",
    "\n",
    "Going forward with the 2nd Exercise, this is now how to visualize the provided, wrangled dataframe wherein the .melt()\n",
    "function is used in order to turn the dataframe that is in a wide format, which is simply the format wherin the provided\n",
    "columns are already located individually on the top while the data entries are located under them row by row, turning\n",
    "them into a long format, which is a format where the columns are minimized and the data values can be visualized by\n",
    "looking at under the variable column which contains the given variables you want to lessen in the columns and the value\n",
    "columns which contains the values of those given in each variable columns.\n",
    "\n",
    "Lastly for the 3rd Exercise, this now contains the data scrapping for python. Based on my understanding, data scrapping\n",
    "simply consist of utilizing the provided URLs of a specific website that you want to extract a data from and using\n",
    "a script or code to do the extraction process. From what I have did, I used the kaggles API wherein the kaggle website\n",
    "consists of numerous publicly available datasets to choose from, using the kaggles API as a medium, the extraction of\n",
    "a selected data is possible which I have done using and based on their documentation. While there are a lot more functions\n",
    "and syntax that is found under their API documentation, all of the important details for this activity is simply how to\n",
    "extract a data which is possible by simply just first generating and activating an API key found under your account details,\n",
    "installing their kaggle modules, then using the !kaggle download -d function to retrieve the dataset themselves."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
